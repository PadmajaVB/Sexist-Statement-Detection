{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SexistCommentDetection.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PadmajaVB/Sexist-Statement-Detection/blob/main/SexistCommentDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhjB3VYNVOSu"
      },
      "source": [
        "#!pip install tensorflow-addons"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0FphptPMkd4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c15932f9-e8e6-4a4b-a5bf-38d0489a75fc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dA47SO9xmsjq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "098a8ec9-8ab6-4d60-9de5-e4e33d9ce725"
      },
      "source": [
        "!pip install tensorflow_addons"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow_addons\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/4b/e893d194e626c24b3df2253066aa418f46a432fdb68250cde14bf9bb0700/tensorflow_addons-0.13.0-cp37-cp37m-manylinux2010_x86_64.whl (679kB)\n",
            "\r\u001b[K     |▌                               | 10kB 22.9MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 17.4MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30kB 14.6MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 13.5MB/s eta 0:00:01\r\u001b[K     |██▍                             | 51kB 7.8MB/s eta 0:00:01\r\u001b[K     |███                             | 61kB 8.2MB/s eta 0:00:01\r\u001b[K     |███▍                            | 71kB 8.7MB/s eta 0:00:01\r\u001b[K     |███▉                            | 81kB 9.7MB/s eta 0:00:01\r\u001b[K     |████▍                           | 92kB 9.2MB/s eta 0:00:01\r\u001b[K     |████▉                           | 102kB 7.6MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 112kB 7.6MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 122kB 7.6MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 133kB 7.6MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 143kB 7.6MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 153kB 7.6MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 163kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 174kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 184kB 7.6MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 194kB 7.6MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 204kB 7.6MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 215kB 7.6MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 225kB 7.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 235kB 7.6MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 245kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████████                    | 256kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 266kB 7.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 276kB 7.6MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 286kB 7.6MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 296kB 7.6MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 307kB 7.6MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 317kB 7.6MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 327kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████████████                | 337kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 348kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 358kB 7.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 368kB 7.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 378kB 7.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 389kB 7.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 399kB 7.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 409kB 7.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 419kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 430kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 440kB 7.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 450kB 7.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 460kB 7.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 471kB 7.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 481kB 7.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 491kB 7.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 501kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 512kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 522kB 7.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 532kB 7.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 542kB 7.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 552kB 7.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 563kB 7.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 573kB 7.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 583kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 593kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 604kB 7.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 614kB 7.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 624kB 7.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 634kB 7.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 645kB 7.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 655kB 7.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 665kB 7.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 675kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 686kB 7.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.13.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhk9tctaQQpB"
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re\n",
        "import collections\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model, Sequential,model_from_json, load_model\n",
        "from tensorflow.keras.layers import Input, LSTM, SimpleRNN, Embedding, Dense, Flatten, RepeatVector, Permute, Activation, Dropout, Bidirectional, Multiply, Lambda"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eO6WjrntR09"
      },
      "source": [
        "## Loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KmZh2i2RKDE"
      },
      "source": [
        "data_path = '/content/drive/MyDrive/UnivAI/AI-3 Project/data/ISEP Sexist Data labeling.xlsx'\n",
        "data  = pd.read_excel(data_path)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "wWdnxqzEiDh6",
        "outputId": "5690deb4-58c9-45b6-8bbe-2944d898f2c3"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentences</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>For a woman, that is good</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Just dress sexy and you will sign any contract.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Are you having period ?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stop being bitchy</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I leave early because of her children instead ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           Sentences  Label\n",
              "0                          For a woman, that is good      1\n",
              "1    Just dress sexy and you will sign any contract.      1\n",
              "2                            Are you having period ?      1\n",
              "3                                  Stop being bitchy      1\n",
              "4  I leave early because of her children instead ...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeylgL1TxsxV"
      },
      "source": [
        "def clean_data(df):\n",
        "  df.Sentences = [element.lower() for element in df.Sentences]\n",
        "  df.Sentences = [re.sub(r'[^a-zA-Z /n]', '', element) for element in df.Sentences]\n",
        "  # df.Sentences = ['<s> '+ element + ' </s>' for element in df.Sentences]\n",
        "  return df"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQXQTRMYxtol"
      },
      "source": [
        "df = clean_data(data)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "1toE-6nhiG7B",
        "outputId": "7573a6f4-d1ac-414e-d9f9-14357794060a"
      },
      "source": [
        "df['Label'].value_counts().plot(kind='bar')\n",
        "plt.xlabel('label category')\n",
        "plt.ylabel('count')\n",
        "plt.title('Sexist comment distribution in the dataset')\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nvc7OzPtNAB"
      },
      "source": [
        "## Train-test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNBrmsPbtQXw"
      },
      "source": [
        "X = df[['Sentences']]\n",
        "y = df.Label\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state = 66, stratify=y)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C86IXOZTm1OL"
      },
      "source": [
        "#!unzip '/content/drive/MyDrive/UnivAI/AI-3 Project/Embeddings/1b-GNGloVe-300d-0.8-0.8.zip' -d '/content/drive/MyDrive/UnivAI/AI-3 Project/Embeddings/'"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFtlBSBMuEtf"
      },
      "source": [
        "### Loading the Gender neutral GLoVe embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANZPM5CmhyOW"
      },
      "source": [
        "def read_glove_vecs(glove_file):\n",
        "    with open(glove_file, encoding=\"utf8\") as f:\n",
        "        words = set()\n",
        "        word_to_vec_map = {}\n",
        "        for line in f:\n",
        "            line = line.strip().split()\n",
        "            curr_word = line[0]\n",
        "            words.add(curr_word)\n",
        "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
        "        \n",
        "        i = 1\n",
        "        words_to_index = {}\n",
        "        index_to_words = {}\n",
        "        for w in sorted(words):\n",
        "            words_to_index[w] = i\n",
        "            index_to_words[i] = w\n",
        "            i = i + 1\n",
        "    return words_to_index, index_to_words, word_to_vec_map"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-XGDGMLi1s-"
      },
      "source": [
        "embedding_path = '/content/drive/MyDrive/UnivAI/AI-3 Project/Embeddings/1b-vectors300-0.8-0.8.txt'\n",
        "words_to_index, index_to_words, word_to_vec_map = read_glove_vecs(embedding_path)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSb0Nv5HmzbU",
        "outputId": "160ec4bf-d1b3-447d-d380-69a0efbbd645"
      },
      "source": [
        "word_to_vec_map['and'].shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYEOZlatulo1"
      },
      "source": [
        "vocab = list(words_to_index.keys())"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6cZK0YronTS",
        "outputId": "5b77954d-1bdd-461a-85cd-ac35000fe17c"
      },
      "source": [
        "len(vocab)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "142527"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbWhTQxvuMEz"
      },
      "source": [
        "### Getting word embeddigs for the input data - X_train and X_test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzCUzLfPpArL"
      },
      "source": [
        "def get_tokens_embedding_list(data, vocab, word_to_vec_map):\n",
        "  embedding_list = []\n",
        "  for sent_seq in data:\n",
        "    tensor_list=[]\n",
        "    for word in sent_seq[0].split():\n",
        "      if word in vocab:\n",
        "        tensor_list.append(word_to_vec_map[word])\n",
        "        # print(len(tensor_list))\n",
        "    embedding_list.append(tensor_list)\n",
        "  return embedding_list"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C50-ku8LtBWD"
      },
      "source": [
        "X_train_embedding = get_tokens_embedding_list(X_train.values, vocab, word_to_vec_map)\n",
        "X_test_embedding = get_tokens_embedding_list(X_test.values, vocab, word_to_vec_map)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NY712TvSpQf"
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_train_embedding, y_train, train_size=0.9, random_state=66)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ay-6PX2xuXBd",
        "outputId": "b9b857cb-ee2a-448f-ab5b-fc120b1d3308"
      },
      "source": [
        "len(X_train_embedding), len(X_train), len(X_test_embedding)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(909, 818, 228)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VA4E7RgtvMxi",
        "outputId": "d2527f36-9114-4852-8452-663413dcd01b"
      },
      "source": [
        "np.array(X_train[0]).shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5Z_7VUUm36j"
      },
      "source": [
        "def create_dataset(data_in, target_in):\n",
        "   \n",
        "    #Get the length of each sentence\n",
        "    N = [len(data_in[i]) for i, _ in enumerate(data_in)]\n",
        "    embedding_size = 300\n",
        "    tensor_N = tf.constant(N, tf.int32)\n",
        "    ragged_input  = tf.ragged.constant(data_in, dtype=tf.float32)\n",
        "    print(ragged_input.shape)\n",
        "\n",
        "    # Build the dataset and the operations\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((ragged_input, target_in))\n",
        "    del ragged_input\n",
        "\n",
        "    dataset = dataset.shuffle(1000)\n",
        "    dataset = dataset.batch(32)\n",
        "    \n",
        "    # Transform_pad function is defined above; you can change the num_parallel_calls\n",
        "    dataset = dataset.map(lambda x,y: (x.to_tensor(default_value=0, shape=[None, None, embedding_size]), y), num_parallel_calls=3)   \n",
        "                          \n",
        "    dataset = dataset.prefetch(1)\n",
        "    return dataset"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmEK4qIQSARA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e284c762-73d6-4151-b806-4b4718cbf06e"
      },
      "source": [
        "train_dataset = create_dataset(X_train, y_train)\n",
        "val_dataset = create_dataset(X_val, y_val)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(818, None, None)\n",
            "(91, None, None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IZ-86rZT7oe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1edc5368-ca77-4bde-a6ae-ae83012b241b"
      },
      "source": [
        "train_dataset"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((None, None, 300), (None,)), types: (tf.float32, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B62CItjH2wU5"
      },
      "source": [
        "### Define the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffRZ381EwVQo"
      },
      "source": [
        "input_layer = Input((None, 300), name='input')\n",
        "bid_lstm_1 = Bidirectional(LSTM(128, return_sequences=True))(input_layer)\n",
        "dropout_1 = Dropout(0.5)(bid_lstm_1)\n",
        "bid_lstm_2 = Bidirectional(LSTM(128, return_sequences=False))(dropout_1)\n",
        "dropout_2 = Dropout(0.5)(bid_lstm_2)\n",
        "dense = Dense(1, activation='sigmoid')(dropout_2)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=dense)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7he80iz31fr",
        "outputId": "c98897e3-4b5d-4531-a495-ca6222edbcfd"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, None, 300)]       0         \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, None, 256)         439296    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, None, 256)         0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 256)               394240    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 833,793\n",
            "Trainable params: 833,793\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbTGrKWC4pAY"
      },
      "source": [
        "model.compile(optimizer='adam', loss='bce', metrics=tfa.metrics.F1Score(num_classes=2, average='micro'))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gnOGWd05BRM"
      },
      "source": [
        "history = model.fit(train_dataset, epochs=10, validation_data=val_dataset, verbose=1)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GABMYB3Zk2C"
      },
      "source": [
        "ragged_input_test  = tf.ragged.constant(X_test_embedding, dtype=tf.float32)\n",
        "dataset = tf.data.Dataset.from_tensor_slices((ragged_input_test, y_test))\n",
        "dataset = dataset.shuffle(1000)\n",
        "dataset = dataset.batch(1)\n",
        "test_dataset = dataset.map(lambda x,y: (x.to_tensor(default_value=0, shape=[None, None, 300]),y), num_parallel_calls=3)\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-LhxO3q6OKy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "322471da-0a10-4196-8646-ff869e08910e"
      },
      "source": [
        "loss, f_score = model.evaluate(test_dataset)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "228/228 [==============================] - 8s 5ms/step - loss: 0.6960 - f1_score: 0.7082\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6jf2Xd6LUmT"
      },
      "source": [
        "## Model with attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ic7H3XtwLYYw"
      },
      "source": [
        "input_layer = Input((None, 300), name='input')\n",
        "bid_lstm_1 = Bidirectional(LSTM(128, return_sequences=True))(input_layer)\n",
        "dropout_1 = Dropout(0.5)(bid_lstm_1)\n",
        "\n",
        "attention = Dense(1, activation='tanh')(dropout_1)\n",
        "attention = Flatten()(attention)\n",
        "attention = Activation('softmax')(attention)\n",
        "attention = RepeatVector(128 * 2)(attention)\n",
        "attention = Permute([2, 1])(attention)\n",
        "\n",
        "sent_representation = Multiply()([dropout_1, attention])\n",
        "sent_representation = Lambda(lambda xin: K.sum(xin, axis=1))(sent_representation)\n",
        "\n",
        "dropout_2 = Dropout(0.5)(sent_representation)\n",
        "dense = Dense(1, activation='sigmoid')(dropout_2)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=dense)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppDUmA6LLaUW",
        "outputId": "44925539-c578-4ea2-f770-42ecdfb981b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input (InputLayer)              [(None, None, 300)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_2 (Bidirectional) (None, None, 256)    439296      input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, None, 256)    0           bidirectional_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, None, 1)      257         dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, None)         0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, None)         0           flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector (RepeatVector)    (None, 256, None)    0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "permute (Permute)               (None, None, 256)    0           repeat_vector[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "multiply (Multiply)             (None, None, 256)    0           dropout_2[0][0]                  \n",
            "                                                                 permute[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 256)          0           multiply[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 256)          0           lambda[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1)            257         dropout_3[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 439,810\n",
            "Trainable params: 439,810\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZm0UQyyPm0B"
      },
      "source": [
        "model.compile(optimizer='adam', loss='bce', metrics=tfa.metrics.F1Score(num_classes=2, average='micro'))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWf0IWEXPuPC",
        "outputId": "583536c0-8259-4b4e-c74d-07d46c4d1abd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "history = model.fit(train_dataset, epochs=10, validation_data=val_dataset, verbose=1)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "23/26 [=========================>....] - ETA: 0s - loss: 0.6141 - f1_score: 0.7054"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py:257: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  'consistency.' % (self.__class__.__name__,))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "26/26 [==============================] - 4s 36ms/step - loss: 0.6106 - f1_score: 0.7077 - val_loss: 0.6082 - val_f1_score: 0.7183\n",
            "Epoch 2/10\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.4463 - f1_score: 0.7077 - val_loss: 0.4749 - val_f1_score: 0.7183\n",
            "Epoch 3/10\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.3674 - f1_score: 0.7077 - val_loss: 0.4826 - val_f1_score: 0.7183\n",
            "Epoch 4/10\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.3289 - f1_score: 0.7077 - val_loss: 0.4868 - val_f1_score: 0.7183\n",
            "Epoch 5/10\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.2922 - f1_score: 0.7077 - val_loss: 0.3810 - val_f1_score: 0.7183\n",
            "Epoch 6/10\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.2801 - f1_score: 0.7077 - val_loss: 0.3994 - val_f1_score: 0.7183\n",
            "Epoch 7/10\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.2380 - f1_score: 0.7077 - val_loss: 0.4469 - val_f1_score: 0.7183\n",
            "Epoch 8/10\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.1915 - f1_score: 0.7077 - val_loss: 0.4468 - val_f1_score: 0.7183\n",
            "Epoch 9/10\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.1780 - f1_score: 0.7077 - val_loss: 0.7015 - val_f1_score: 0.7183\n",
            "Epoch 10/10\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.1372 - f1_score: 0.7077 - val_loss: 0.6405 - val_f1_score: 0.7183\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59_TuW42KylM"
      },
      "source": [
        "### Script to get the data for everyday Sexism project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4D1R9JiNWiK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 820
        },
        "outputId": "cc60b56d-73e7-4b35-c722-8747e7d9e94c"
      },
      "source": [
        "!pip install ipdb"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ipdb\n",
            "  Downloading https://files.pythonhosted.org/packages/5f/43/eb2be141dac56e502b6e35c1e4a9b1bbb2d4dcbec773c0f6563e79758909/ipdb-0.13.8.tar.gz\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from ipdb) (56.1.0)\n",
            "Collecting ipython>=7.17.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/81/d1/8d0ba7589ea4cbf3e80ef8e20616da2cfc3c33187a64b044372aad517512/ipython-7.23.1-py3-none-any.whl (785kB)\n",
            "\u001b[K     |████████████████████████████████| 788kB 9.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: toml>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from ipdb) (0.10.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipdb) (4.4.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0->ipdb) (0.18.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0->ipdb) (0.1.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0->ipdb) (0.7.5)\n",
            "Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/eb/e6/4b4ca4fa94462d4560ba2f4e62e62108ab07be2e16a92e594e43b12d3300/prompt_toolkit-3.0.18-py3-none-any.whl (367kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 21.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0->ipdb) (5.0.5)\n",
            "Requirement already satisfied: pexpect>4.3; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0->ipdb) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0->ipdb) (2.6.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0->ipdb) (0.2.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython>=7.17.0->ipdb) (0.8.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.17.0->ipdb) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython>=7.17.0->ipdb) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3; sys_platform != \"win32\"->ipython>=7.17.0->ipdb) (0.7.0)\n",
            "Building wheels for collected packages: ipdb\n",
            "  Building wheel for ipdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ipdb: filename=ipdb-0.13.8-cp37-none-any.whl size=11599 sha256=d839fd73980ff3fe86fe9f9ed5af4b3dc5f8d906d28d4410b1267be7ab091db3\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/d6/5a/2fdf30b75ca5099e18f66a0a4d439ba031e1aa239e12b39c24\n",
            "Successfully built ipdb\n",
            "\u001b[31mERROR: jupyter-console 5.2.0 has requirement prompt-toolkit<2.0.0,>=1.0.0, but you'll have prompt-toolkit 3.0.18 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement ipython~=5.5.0, but you'll have ipython 7.23.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: prompt-toolkit, ipython, ipdb\n",
            "  Found existing installation: prompt-toolkit 1.0.18\n",
            "    Uninstalling prompt-toolkit-1.0.18:\n",
            "      Successfully uninstalled prompt-toolkit-1.0.18\n",
            "  Found existing installation: ipython 5.5.0\n",
            "    Uninstalling ipython-5.5.0:\n",
            "      Successfully uninstalled ipython-5.5.0\n",
            "Successfully installed ipdb-0.13.8 ipython-7.23.1 prompt-toolkit-3.0.18\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "IPython",
                  "prompt_toolkit"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2D3qViJNq0u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f5bf105-c6ae-4b4e-b1d2-178d3cdd927b"
      },
      "source": [
        "!apt-get install libmagic-dev\n",
        "!pip install python-magic"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libmagic-mgc libmagic1\n",
            "Suggested packages:\n",
            "  file\n",
            "The following NEW packages will be installed:\n",
            "  libmagic-dev libmagic-mgc libmagic1\n",
            "0 upgraded, 3 newly installed, 0 to remove and 34 not upgraded.\n",
            "Need to get 332 kB of archives.\n",
            "After this operation, 5,552 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic-mgc amd64 1:5.32-2ubuntu0.4 [184 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic1 amd64 1:5.32-2ubuntu0.4 [68.6 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic-dev amd64 1:5.32-2ubuntu0.4 [79.7 kB]\n",
            "Fetched 332 kB in 1s (227 kB/s)\n",
            "Selecting previously unselected package libmagic-mgc.\n",
            "(Reading database ... 160706 files and directories currently installed.)\n",
            "Preparing to unpack .../libmagic-mgc_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking libmagic-mgc (1:5.32-2ubuntu0.4) ...\n",
            "Selecting previously unselected package libmagic1:amd64.\n",
            "Preparing to unpack .../libmagic1_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n",
            "Selecting previously unselected package libmagic-dev:amd64.\n",
            "Preparing to unpack .../libmagic-dev_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking libmagic-dev:amd64 (1:5.32-2ubuntu0.4) ...\n",
            "Setting up libmagic-mgc (1:5.32-2ubuntu0.4) ...\n",
            "Setting up libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n",
            "Setting up libmagic-dev:amd64 (1:5.32-2ubuntu0.4) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Collecting python-magic\n",
            "  Downloading https://files.pythonhosted.org/packages/ba/7c/1d1d4bdda29bfec662b9b50951dee2dddf7747d3cbf7777f3d1c63372bd0/python_magic-0.4.22-py2.py3-none-any.whl\n",
            "Installing collected packages: python-magic\n",
            "Successfully installed python-magic-0.4.22\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tzpYpiKv4sB",
        "outputId": "98a5d504-dc63-4b22-e6ed-4575a8d4aa3c"
      },
      "source": [
        "!pip install ftfy"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ftfy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/da/d215a091986e5f01b80f5145cff6f22e2dc57c6b048aab2e882a07018473/ftfy-6.0.3.tar.gz (64kB)\n",
            "\r\u001b[K     |█████                           | 10kB 25.0MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 20kB 18.2MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 30kB 15.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 40kB 14.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 51kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 61kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 5.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy) (0.2.5)\n",
            "Building wheels for collected packages: ftfy\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-6.0.3-cp37-none-any.whl size=41916 sha256=716904f52b70aaf841cf383a11fe4f203a4e08021cda22b0b21c2ad60ba7f1fe\n",
            "  Stored in directory: /root/.cache/pip/wheels/99/2c/e6/109c8a28fef7a443f67ba58df21fe1d0067ac3322e75e6b0b7\n",
            "Successfully built ftfy\n",
            "Installing collected packages: ftfy\n",
            "Successfully installed ftfy-6.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6YVmAjEQC1r"
      },
      "source": [
        "# Example use: python script.py data_placeholders.tsv data.tsv\n",
        "import re\n",
        "import urllib.request as urllib2\n",
        "import os\n",
        "import ipdb\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import sys\n",
        "import codecs\n",
        "import pandas as pd\n",
        "import csv\n",
        "import json\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import io\n",
        "import magic\n",
        "import pickle\n",
        "import ftfy\n",
        "\n",
        "tsv_filepath = '/content/drive/MyDrive/UnivAI/AI-3 Project/data/Everyday Sexism Project/data_placeholders.tsv'\n",
        "data_write_path = '/content/drive/MyDrive/UnivAI/AI-3 Project/data/Everyday Sexism Project/data.tsv'\n",
        "\n",
        "\n",
        "def find_post_id(name_box):\n",
        "    classes = name_box['class']\n",
        "    for _class in classes:\n",
        "        if _class[:5] == \"post-\" and len(_class) > 5:\n",
        "            return int(_class[5:])\n",
        "    return -1\n",
        "\n",
        "\n",
        "def crawl_post(post_page, post_number):\n",
        "    crawl_page = post_page + str(post_number)\n",
        "\n",
        "    isCrawledSuccessfully = False\n",
        "    while not isCrawledSuccessfully:\n",
        "        try:\n",
        "            page = urllib2.urlopen(crawl_page).read()\n",
        "            isCrawledSuccessfully = True\n",
        "        except urllib2.HTTPError as e:\n",
        "            if e.code == 404:\n",
        "                print(\"\\t\\t>>> Found 404\")\n",
        "                return None\n",
        "            else:\n",
        "                print(\"\\t\\t>>> Waitiing for 30 seconds\")\n",
        "                time.sleep(30)\n",
        "        except Exception:\n",
        "            print(\"\\t\\t>>> Waitiing for 30 seconds\")\n",
        "            time.sleep(30)\n",
        "\n",
        "    soup = BeautifulSoup(page, 'html.parser')\n",
        "    name_boxes = soup.find_all('article', attrs={'class': 'post'})\n",
        "    assert len(name_boxes) == 1\n",
        "    for i, name_box in enumerate(name_boxes):\n",
        "        post_id = find_post_id(name_box)\n",
        "        if post_id == -1:\n",
        "            print(\"\\t\\t>>> ERROR: Error fetching post_id\")\n",
        "            return None\n",
        "        \n",
        "        #TODO: VERIFY IF THIS IS CORRECT\n",
        "        soup = BeautifulSoup(name_box.encode(\"utf-8\"), 'html.parser')\n",
        "        _name_box = soup.find('div', attrs={'class': 'entry-content'})\n",
        "        post = _name_box.get_text()\n",
        "        post = post.replace('\\n', '<br/>')\n",
        "    return post\n",
        "\n",
        "\n",
        "import re\n",
        "\n",
        "r_white = re.compile(r'\\s+')\n",
        "\n",
        "xml_csv = open(data_write_path, 'w')\n",
        "csv_writer = csv.writer(xml_csv, delimiter='\\t')\n",
        "csv_writer.writerow(['post', 'labels'])\n",
        "\n",
        "post_id_dict = {}\n",
        "\n",
        "with open(tsv_filepath, 'r') as csvfile:\n",
        "    spamreader = csv.reader(csvfile, delimiter='\\t')\n",
        "    for i, row in enumerate(spamreader):\n",
        "        if i == 0:\n",
        "            continue\n",
        "        labels = row[1]\n",
        "        parts = row[0].split(\"__\")\n",
        "        post_id__str = parts[0]\n",
        "        post_offsets__str = [offset.split(\"_\") for offset in parts[1:]]\n",
        "\n",
        "        if post_id__str in post_id_dict:\n",
        "            print(\"accessing \" + post_id__str)\n",
        "            post_text = post_id_dict[post_id__str]\n",
        "        else:\n",
        "            print(\"fetching \" + post_id__str)\n",
        "            post_text = crawl_post(\"https://everydaysexism.com/everyday-sexism/\", post_id__str)\n",
        "            if post_text == None:\n",
        "                continue\n",
        "            post_id_dict[post_id__str] = post_text\n",
        "\n",
        "        post_text = post_text.replace('<br/>', ' ')\n",
        "        post_text = re.sub(' +', ' ', post_text)\n",
        "        post_text = post_text.lstrip()\n",
        "        post_text__fixed = ftfy.fix_text(post_text)\n",
        "        text = \"\"\n",
        "        for index in range(len(post_offsets__str)):\n",
        "            text = text + post_text__fixed[int(post_offsets__str[index][0]):int(post_offsets__str[index][1]) + 1]\n",
        "            if len(post_offsets__str) > 1 and len(post_offsets__str) != index + 1:\n",
        "                text = text + \" \"\n",
        "        text = r_white.sub(' ', text)\n",
        "        text = text.strip()\n",
        "        csv_writer.writerow([text, labels])\n",
        "\n",
        "xml_csv.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mdpyM9LQEhS"
      },
      "source": [
        "df_es = pd.read_csv(data_write_path, sep='\\t')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}